# Data Engineering

Concepts:

1. [Slowly Changing Dimensions (SCD)](https://adatis.co.uk/introduction-to-slowly-changing-dimensions-scd-types/) by adatis - what can you do when the information in your table changes, types 0-6. Image by Adatis.co.uk.\
   ![](<../../.gitbook/assets/image (17).png>)

Tools

1. [Debezium](https://debezium.io) - an open source distributed platform for change data capture
2. [Hudi](https://hudi.apache.org) - "Hudi is a rich platform to build streaming data lakes with incremental data pipelines on a self-managing database layer, while being optimized for lake engines and regular batch processing."
3. [Upsolver](https://www.upsolver.com) - "Continuous SQL Pipelines for Cloud Data Lakes. No custom coding. No orchestration. No infrastructure maintenance."
4. [DBT](https://www.getdbt.com) - "dbt helps data teams work like software engineersâ€”to ship trusted data, faster. collaboratively deploy analytics code following software engineering best practices like modularity, portability, CI/CD, and documentation. Now anyone who knows SQL can build production-grade data pipelines."
5. [Metorikku](https://github.com/YotpoLtd/metorikku) - A simplified, lightweight ETL Framework based on Apache Spark
6. [redash](https://redash.io) - Connect and query your data sources, build dashboards to visualize data and share them with your company.
7. Metabase
8. Superset
9. Stitch
10. [SnowPlow](https://snowplowanalytics.com) - Generate [complete, accurate and well-structured event data](https://snowplowanalytics.com/web-and-mobile-data/) across all platforms and channels in a common format, with the Snowplow Behavioral Data Platform.
11. [Workato](https://www.workato.com) - A SINGLE PLATFORM FOR INTEGRATION & WORKFLOW AUTOMATION ACROSS YOUR ORGANIZATION
12. [AWS Deequ](https://aws.amazon.com/blogs/big-data/test-data-quality-at-scale-with-deequ/) - Test data quality at scale\


&#x20;
